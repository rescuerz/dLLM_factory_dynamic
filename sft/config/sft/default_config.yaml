model_name: "GSAI-ML/LLaDA-8B-Instruct"    # 预训练模型名称
local_batch_size: 2                        # 训练批次大小
max_length: 4096                           # 分词最大长度
num_epochs: 20                             # 训练轮数
learning_rate: 1e-5                        # 优化器学习率
grad_accum_steps: 1                        # 梯度累积步数
output_dir: "./sft_save"                   # 模型与日志保存目录
job_name: "llada-sft"                      # 任务名称
train_data: "gsm8k"                        # 训练数据路径
max_grad_norm: 1.0                         # 梯度裁剪阈值
weight_decay: 0.1                          # 权重衰减
evaluation_strategy: "steps"               # 评估策略
eval_steps: 100                            # 评估步数
logging_steps: 10                          # 日志记录步数
save_steps: 100                            # 保存步数
save_total_limit: 20                       # 最大保存检查点数量
load_best_model_at_end: true              # 训练结束时加载最佳模型
bf16: true                                 # 使用bfloat16精度
report_to: "none"                          # 报告工具，在配置完成 wandb 之后，可选"wandb"
remove_unused_columns: false               # 是否移除未使用的列

# 动态长度微调配置
enable_dynamic_length: true             # 是否启用动态长度微调（默认禁用，确保向后兼容）

# 动态长度详细配置
dynamic_length:
  # 训练策略配置
  initial_response_length: 64             # 初始response训练长度
  expansion_steps: [64, 128, 256, 512, 1024, 2048]  # 渐进式扩展步骤
  max_expansions: 5                       # 最大扩展次数
  confidence_threshold: 0.7             # 扩展决策置信度阈值
  expansion_check_ratio: 0.35           # 扩展检查比例 (30%-40%)
  exclude_from_attention: false        # 是否将特殊token排除在注意力机制之外
  exclude_special_tokens_in_training: false # 是否在训练时排除特殊token